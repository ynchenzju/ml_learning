FM思想：单纯的线性模型，拟合不足，而各个特征之间可能是有相互联系的(比如”男性“和”篮球“的联系)，因此自然就想到在线性模型上加二次项进行拟合。增加模型表达能力。
虽然理论上FM可以对高阶特征组合进行建模，但因为计算复杂度的原因，FM一般只用到了二阶特征组合，

---

二次项拟合的困难：输入数据非常稀疏，且因二次项系数有n^2个线性无关的系数，因此很容易导致训练不充分。

针对系数太多的问题，考虑对n*n的对称实矩阵进行特征分解。把n*n的矩阵，分解成两个n*k矩阵相乘的形式，以减少参数数目。通过矩阵分解达到减少参数的思想，在svd分解中有说明：https://blog.csdn.net/billbliss/article/details/78579308

---

对矩阵进行分解后的表达式，<Vi, Vj>对应于原表达式中Wij，但是，前者两个V向量不是相互独立的，因此两者相乘大概率不为0。但原式中的Wij，若xi和xj的乘积为0，则Wij也为0。这在一定程度上解决了数据稀疏带来的训练问题。

通过ab+ac+bc=1/2 * [(a+b+c)^2 -(a^2+b^2+c^2)]的trick，可以将表达式化简到式子中只出现xi。因此对Vi,f的训练，只需要样本xi特征非0，适用于稀疏数据。

FM训练时间复杂度是O(kn),模型参数数目：nk+n+1。
最后Vi可以看做xi特征的低维度隐向量，类似于word embeding中降维操作。

---

主要参考链接：
https://www.jiqizhixin.com/articles/2018-07-16-17
https://zhuanlan.zhihu.com/p/37963267

---
主要借鉴思想：
1. 特征间组合(在高维空间进行分类)。
2. svd矩阵分解减少参数数量。
3. 隐向量